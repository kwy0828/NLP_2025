{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f28a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# [4/9] Seq2Seq 기본 구조\n",
    "# =============================================\n",
    "# 목표: 인코더-디코더 구조를 이해하고, 간단한 기계 번역 모델을 구현합니다.\n",
    "\n",
    "# --- 1. 기본 설정 및 데이터 준비 ---\n",
    "!pip install torch torchtext transformers datasets sacrebleu\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download fr_core_news_sm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "import spacy\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# --- 2. 데이터셋 및 토크나이저 준비 ---\n",
    "# Multi30k 데이터셋 (영어 -> 프랑스어) 로드\n",
    "raw_datasets = load_dataset(\"multi30k\", \"en-fr\", split=\"train\")\n",
    "\n",
    "# Spacy 토크나이저 로드\n",
    "spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "spacy_fr = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "def tokenize_fr(text):\n",
    "    return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
    "\n",
    "# 간단한 어휘집(Vocabulary) 클래스\n",
    "class Vocab:\n",
    "    def __init__(self, tokenizer, min_freq=2):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.itos = {0: \"<pad>\", 1: \"<sos>\", 2: \"<eos>\", 3: \"<unk>\"}\n",
    "        self.stoi = {v: k for k, v in self.itos.items()}\n",
    "        \n",
    "    def build_vocab(self, sentences):\n",
    "        counter = Counter()\n",
    "        for sentence in sentences:\n",
    "            counter.update(self.tokenizer(sentence))\n",
    "        \n",
    "        for word, count in counter.items():\n",
    "            if count >= 2:\n",
    "                idx = len(self.itos)\n",
    "                self.itos[idx] = word\n",
    "                self.stoi[word] = idx\n",
    "\n",
    "# 어휘집 생성\n",
    "SRC_VOCAB = Vocab(tokenize_en)\n",
    "TRG_VOCAB = Vocab(tokenize_fr)\n",
    "SRC_VOCAB.build_vocab(d['en'] for d in raw_datasets)\n",
    "TRG_VOCAB.build_vocab(d['fr'] for d in raw_datasets)\n",
    "\n",
    "# --- 3. Encoder, Decoder 클래스 작성 ---\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src: [src_len, batch_size]\n",
    "        embedded = self.embedding(src) # [src_len, batch_size, emb_dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input: [batch_size]\n",
    "        input = input.unsqueeze(0) # [1, batch_size]\n",
    "        embedded = self.embedding(input) # [1, batch_size, emb_dim]\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0)) # [batch_size, output_dim]\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "# --- 4. Seq2Seq 모델 래핑 ---\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        # src: [src_len, batch_size]\n",
    "        # trg: [trg_len, batch_size]\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = len(TRG_VOCAB.itos)\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        # 첫 번째 입력은 <sos> 토큰\n",
    "        input = trg[0, :]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            \n",
    "            # Teacher Forcing: 다음 입력을 실제 정답으로 할지, 모델 예측으로 할지 결정\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs\n",
    "\n",
    "# --- 5. 모델 학습 (간략화된 루프) ---\n",
    "INPUT_DIM = len(SRC_VOCAB.itos)\n",
    "OUTPUT_DIM = len(TRG_VOCAB.itos)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "enc = EncoderRNN(INPUT_DIM, ENC_EMB_DIM, HID_DIM)\n",
    "dec = DecoderRNN(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM)\n",
    "model = Seq2Seq(enc, dec, DEVICE).to(DEVICE)\n",
    "\n",
    "# (실제 학습 코드는 데이터 전처리, 배치화, 학습 루프 등 더 복잡합니다.)\n",
    "print(\"Seq2Seq 모델 구조가 정의되었습니다.\")\n",
    "print(\"실습 과제: Teacher Forcing 비율을 0.0, 0.5, 1.0으로 바꿔가며 학습 속도와 번역 품질 변화를 관찰해보세요.\")\n",
    "# (BLEU 스코어 계산은 sacrebleu 라이브러리를 사용해 구현할 수 있습니다)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
